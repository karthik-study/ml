{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f2b686",
   "metadata": {},
   "source": [
    "# End to End Machine Learning With Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ffad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "333d6ed2",
   "metadata": {},
   "source": [
    "### Part1- EDA of the Medical Dataset\n",
    "1. Import the libraries\n",
    "2. Load and View the data\n",
    "3. Clean the data\n",
    "4. Complete EDA of the data ( depoloy a EDA page in streamlit) \n",
    "\n",
    "### Part2-Modelling of the data set\n",
    "5. Preprocessing for modelling\n",
    "6. Fit and Evaluate various models\n",
    "7. OPtimize the chosen model\n",
    "8. Interpret the model\n",
    "9. Create a pipeline for the model\n",
    "10. Pickle the model \n",
    "11. Deploy the model in streamlit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c5037",
   "metadata": {},
   "source": [
    "### Step1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d0d61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb21fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb0ff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9\n"
     ]
    }
   ],
   "source": [
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d7c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\pc\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019b7078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\pc\\anaconda3i\\lib\\site-packages (1.7.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\pc\\anaconda3i\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\anaconda3i\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98f812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
      "Collecting cachetools>=4.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: requests>=2.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (2.28.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Collecting rich>=10.11.0\n",
      "  Using cached rich-13.3.5-py3-none-any.whl (238 kB)\n",
      "Collecting protobuf<4,>=3.12\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "Collecting pyarrow>=4.0\n",
      "  Using cached pyarrow-12.0.0-cp310-cp310-win_amd64.whl (21.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (4.4.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (9.4.0)\n",
      "Collecting tzlocal>=1.1\n",
      "  Using cached tzlocal-5.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting gitpython!=3.1.19\n",
      "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: toml in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: tornado>=6.0.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Collecting blinker>=1.0.0\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting pympler>=0.9\n",
      "  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (22.0)\n",
      "Requirement already satisfied: watchdog in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Collecting altair<5,>=3.2.0\n",
      "  Using cached altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (8.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (1.23.5)\n",
      "Collecting validators>=0.2\n",
      "  Using cached validators-0.20.0-py3-none-any.whl\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Using cached pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (4.11.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\pc\\anaconda3\\lib\\site-packages (from altair<5,>=3.2.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\pc\\anaconda3\\lib\\site-packages (from altair<5,>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from altair<5,>=3.2.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from altair<5,>=3.2.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\lib\\site-packages (from click>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->streamlit) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pandas<3,>=0.25->streamlit) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from validators>=0.2->streamlit) (5.1.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jinja2->altair<5,>=3.2.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (0.18.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: validators, tzdata, smmap, pympler, pygments, pyarrow, protobuf, mdurl, cachetools, blinker, tzlocal, pydeck, markdown-it-py, gitdb, rich, gitpython, altair, streamlit\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed altair-4.2.2 blinker-1.6.2 cachetools-5.3.0 gitdb-4.0.10 gitpython-3.1.31 markdown-it-py-2.2.0 mdurl-0.1.2 protobuf-3.20.3 pyarrow-12.0.0 pydeck-0.8.1b0 pygments-2.15.1 pympler-1.0.1 rich-13.3.5 smmap-5.0.0 streamlit-1.22.0 tzdata-2023.3 tzlocal-5.0.1 validators-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ebe222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\pc\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.1\n",
      "    Uninstalling scikit-learn-1.2.1:\n",
      "      Successfully uninstalled scikit-learn-1.2.1\n",
      "Successfully installed scikit-learn-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda update -c conda-forge scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "print(\"All needed libraries are imported\")\n",
    "\n",
    "\n",
    "# libraries for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# libraries for modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn. tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# libraries for model evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#library for deployement\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc91fa2",
   "metadata": {},
   "source": [
    "### Step2. Load and View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4461912",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0915741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[~data.applymap(np.isreal).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da759d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c94ea6",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Data has 768 rows and 10 columns \n",
    "2. The first column is 'Unnamed: 0' which is redundant\n",
    "3. All columns are numerical except the Outcome \n",
    "4. There are no nulls in the data \n",
    "5. However there are nulls present as 0's\n",
    "6. There are no duplicates or corrupt characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef9dfd",
   "metadata": {},
   "source": [
    "### Step 3. Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the redundant columns\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b599d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerofill=lambda x:x.replace(0, x.median())\n",
    "cols=data.columns[1:6]\n",
    "data[cols]=data[cols].apply(zerofill, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'Yes':1, 'No':0}\n",
    "df=data.copy()\n",
    "df['Outcome']=df['Outcome'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77323ea5",
   "metadata": {},
   "source": [
    "### Step4. Complete EDA of the data ( depoloy a EDA page in streamlit) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a16cd",
   "metadata": {},
   "source": [
    "**Univariate Analysis**\n",
    "1. Numericals -histograms and boxplots \n",
    "2. Categorical- barcharts \n",
    "\n",
    "**Bivariate Analysis**\n",
    "1. Categorical vs Numerical barchart\n",
    "2. Scatter plots and Line plots \n",
    "3. Pairplots \n",
    "\n",
    "**Corralations**\n",
    "1. Correlation Matrix\n",
    "2. Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da64286c",
   "metadata": {},
   "source": [
    "**Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c84910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms(data):\n",
    "    print('Histograms')\n",
    "    data.hist()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_histplot(data, feature, bins=None, figsize=(12,7)):\n",
    "    print(\"Boxplot and Histplot for \", feature)\n",
    "    fig, (ax_box, ax_hist)=plt.subplots(\n",
    "    nrows=2,\n",
    "    sharex=True,\n",
    "    gridspec_kw={'height_ratios':(0.25, 0.75)},\n",
    "    figsize=figsize)\n",
    "    \n",
    "    sns.boxplot(data=data, x=feature, showmeans=True, color='orange', ax=ax_box)\n",
    "    sns.histplot(data=data, x=feature, bins=bins, ax=ax_hist, pallete='green') if bins else sns.\\\n",
    "                         histplot(data=data, x=feature, ax=ax_hist)\n",
    "    ax_hist.axvline(data[feature].mean(), color='green', linestyle='--')\n",
    "    ax_hist.axvline(data[feature].median(), color='black', linestyle='-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(exclude='O').columns:\n",
    "    boxplot_histplot(data=data, feature=col, bins=None, figsize=(12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef553ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barchart(data, feature):\n",
    "    print(\"Univariate Countplot of \", feature)\n",
    "    plt.figure(figsize=(12,7))\n",
    "    ax=sns.countplot(data=data, x=feature, color='green')\n",
    "    for p in ax.patches:\n",
    "        x=p.get_bbox().get_points()[:,0]\n",
    "        y=p.get_bbox().get_points()[1,1]\n",
    "        ax.annotate(\"{:.3g}%\".format(100.*y/len(df)), (x.mean(), y), ha='center', va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "barchart(data=data, feature='Outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262f235",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Insulin . DPF and Age are highly right skewed and having heavy amoiunt of outliers ( we may need to do data transformation like log) \n",
    "2. Age and Pregnancies are also right skewed with some extreme values which may be legit ( need to consukt with domain experts)\n",
    "3. Outcome variable is highly imbalanced(Yes:No = 1:2) , we need to solve for data imbalance before modelling\n",
    "4. Missing values have been taken care of\n",
    "5. Label Encoding is done "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4484203",
   "metadata": {},
   "source": [
    "**Bivariate Analysis**\n",
    "1. Categorical vs Numerical barchart\n",
    "2. Scatter plots and Line plots \n",
    "3. Pairplots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catnum(data, feature1, feature2):\n",
    "    print(\"Bivariate Barchart between {0} and {1}\".format(feature1, feature2))\n",
    "    data.groupby(feature1)[feature2].mean().plot(kind='bar', color='orange')\n",
    "    plt.ylabel(col)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(exclude='O').columns:\n",
    "    catnum(data=data, feature1='Outcome', feature2=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot_scatterplot(data, feature1, feature2):\n",
    "    plt.figure(figsize=(16,7))\n",
    "    print(\"Bivariate Charts for {0} and {1}\".format(feature1, feature2))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.lineplot(data=data, x=feature1, y=feature2, color='green')\n",
    "    plt.title('Lineplot between features')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    sns.scatterplot(data=data, x=feature1, y=feature2, color='orange')\n",
    "    plt.title('Scatterplot between features')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8361c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(exclude='O').columns:\n",
    "    lineplot_scatterplot(data=df, feature1='Glucose', feature2=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b685722",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64b8d9",
   "metadata": {},
   "source": [
    "**Corralations**\n",
    "1. Correlation Matrix\n",
    "2. Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c87f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[:]].corr()['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='Spectral', vmin=-1, vmax=+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a9c15",
   "metadata": {},
   "source": [
    "**Observations of Bivariate Analysis**\n",
    "1. Women with higher Pregnancies, Glucose, DPF, Insulin are more likely to be diabetic\n",
    "2. Glucose and Insulin, BMI and SkinThickness appear to have hiugh multicollinearity\n",
    "3. Glucose, BMI appear to be strongest predictors of Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7c38f",
   "metadata": {},
   "source": [
    "### App for EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db53060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile eda.py\n",
    "import streamlit as st\n",
    "st.title(\"The EDA Page\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "### Step2. Load and View the data\n",
    "\n",
    "data=pd.read_csv('data.csv')\n",
    "st.subheader('Data View')\n",
    "st.write(data.head())\n",
    "\n",
    "st.subheader('Descriptives')\n",
    "st.write(data.describe().T)\n",
    "\n",
    "data.hist()\n",
    "st.subheader('Histograms')\n",
    "plt.tight_layout()\n",
    "st.pyplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267809b",
   "metadata": {},
   "source": [
    "# End of Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf403b",
   "metadata": {},
   "source": [
    "# step 5:data preproccesing\n",
    "1. separate features and the labels\n",
    "2. null value imputation\n",
    "3. label encoding\n",
    "4. data imbalanced solving\n",
    "5. train test split\n",
    "6. feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d90e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data,label):\n",
    "    x=data.drop(label,axis=1)\n",
    "    y=data[label]\n",
    "    sm=SMOTE()\n",
    "    x,y=sm.fit_resample(x,y)\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa07009",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=preprocess(df,'Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c434e4",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "\n",
    "Fit and evalute models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1875b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test,y_pred,model_name):\n",
    "    print('the results of the model',model_name)\n",
    "    print('')\n",
    "    print('accuracy_score=',accuracy_score(y_test,y_pred))\n",
    "    print('')\n",
    "    print('recall_score=',recall_score(y_test,y_pred))\n",
    "    print('')\n",
    "    print('precision=',precision_score(y_test,y_pred))\n",
    "    print('')\n",
    "    print('f1_score=',f1_score(y_test,y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef134b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(clf,x_test,y_test,model_name):\n",
    "    plot_confusion_matrix(clf,x_test,y_test,display_labels=[0,1])\n",
    "    print('')\n",
    "    plot_roc_curve(clf,x_test,y_test)\n",
    "    print('')\n",
    "    plot_precision_recall_curve(clf,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc30d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Outcome']\n",
    "y.value_counts()\n",
    "x=df.drop('Outcome',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8080916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=SMOTE()\n",
    "x,y=sm.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the knn method\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "print_metrics(y_pred,y_test,'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6faffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(knn,x_test, y_test,'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize k\n",
    "neighbors=np.arange(1,20)\n",
    "train_accuracies=np.empty(len(neighbors))\n",
    "test_accuracies=np.empty(len(neighbors))\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    train_accuracies[i]=knn.score(x_train,y_train)\n",
    "    test_accuracies[i]=knn.score(x_test,y_test)\n",
    "\n",
    "plt.plot(neighbors, train_accuracies, label='Train_accuracies')\n",
    "plt.plot(neighbors, test_accuracies, label='Test_accuracies')\n",
    "plt.legend()\n",
    "plt.title(\"Model Complexity Curves\")\n",
    "plt.xlabel(\"No.of.Neighbors\")\n",
    "plt.ylabel(\"Accuraries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5335e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#refit the model\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=16)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "print_metrics(y_pred,y_test,'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4feb8ac",
   "metadata": {},
   "source": [
    "# fit and evaluate all the modeland choose the best to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clfs = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'RandomForestClassifier':RandomForestClassifier(),\n",
    "    'AdaBoostClassifier':AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "    'XGBClassifier':XGBClassifier(),\n",
    "    'SVM':SVC()\n",
    "}\n",
    "\n",
    "# create an empty dataframe of metrics\n",
    "models_report = pd.DataFrame(columns=['Model_name','Accuracy','Recall','Precision',\n",
    "                                    'f1_score'])\n",
    "\n",
    "# fit and evaluate each model\n",
    "for clf, clf_name in list(zip(clfs.values(), clfs.keys())):\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('Fitting Classifier....', clf_name)\n",
    "    y_pred=clf.predict(x_test)\n",
    "    t=pd.Series({\n",
    "        'Model_name':clf_name,\n",
    "        'Accuracy':accuracy_score(y_test, y_pred),\n",
    "        'Recall':recall_score(y_test, y_pred),\n",
    "        'Precision':precision_score(y_test, y_pred),\n",
    "        'f1_score':f1_score(y_test, y_pred)\n",
    "    })\n",
    "    models_report = models_report.append(t, ignore_index=True)\n",
    "    \n",
    "models_report=models_report.sort_values(by='f1_score', ascending=False)\n",
    "models_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8261024",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57561ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize the model using GridSearchCV\n",
    "param_grid={\n",
    "    'n_estimators':[100,150,200,250,300],\n",
    "    'min_samples_leaf':range(1,5,1),\n",
    "    'min_samples_split':range(2,10,2),\n",
    "    'max_depth':[1,2,3,4,5],\n",
    "    'criterion':['entropy','gini'],\n",
    "    \n",
    "}\n",
    "n_folds=3\n",
    "cv=GridSearchCV(estimator=rfc,param_grid=param_grid,cv=n_folds,n_jobs=-1,verbose=5,return_train_score=False)\n",
    "cv.fit(x_train,y_train)\n",
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets interupt the model\n",
    "rfc_tuned=cv.best_estimator_\n",
    "rfc_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02082cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance / model interpretation\n",
    "\n",
    "import shap\n",
    "value=shap.TreeExplainer(rfc).shap_values(x_test)\n",
    "shap.summary_plot(value, x_train, plot_type='bar', feature_names=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the deployement model pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "rfc=rfc_tuned\n",
    "steps=[('sc',sc),('rfc',rfc)]\n",
    "pipeline=Pipeline(steps)\n",
    "x_train,x_test,y_train,y_test=preprocess(df,'Outcome')\n",
    "pipeline.fit(x_train,y_train)\n",
    "y_pred=pipeline.predict(x_test)\n",
    "print_metrics(y_test,y_pred,'Pipeline RFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To freeze the model\n",
    "import pickle\n",
    "model=open('rfc.pickle','wb')\n",
    "pickle.dump(pipeline,model)\n",
    "model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068104bc",
   "metadata": {},
   "source": [
    "# Deploy pickle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cecf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b17cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "st.title('Medical Diagnostic Prediction App')\n",
    "st.markdown('Does the Person have Diabetics')\n",
    "\n",
    "#step1 : load the trained model\n",
    "model=open('rfc.pickle','rb')\n",
    "clf=pickle.load(model)\n",
    "model.close()\n",
    "\n",
    "#step2: get the user input from frontend\n",
    "\n",
    "pregs=st.number_input('Pregnancies',0,20,step=1)\n",
    "glucose=st.slider('Glucose',42,200,40)\n",
    "bp=st.slider('BloodPressure',20,140,20)\n",
    "skin=st.slider('SkinThickness',7,99,7)\n",
    "insulin=st.slider('Insulin',14,850,14)\n",
    "bmi=st.slider('BMI',18,70,18)\n",
    "dpf=st.slider('DiabetesPedigreeFunction',0.05,2.50,0.05)\n",
    "age=st.slider('Age',21,90,21)\n",
    "\n",
    "\n",
    "#step 3: COnvert user input to model input\n",
    "\n",
    "data={\n",
    "    'Pregnancies':pregs,\n",
    "    'Glucose':glucose,\n",
    "    'BloodPressure':bp,\n",
    "    'SkinThickness':skin,\n",
    "    'Insulin':insulin,\n",
    "    'BMI':bmi,\n",
    "    'DiabetesPedigreeFunction':dpf,\n",
    "    'Age':age\n",
    "}\n",
    "\n",
    "input_data=pd.DataFrame([data])\n",
    "\n",
    "# step4 : get the predictions and print the result\n",
    "prediction = clf.predict(input_data)[0]\n",
    "if st.button(\"Predict\"):\n",
    "    if prediction==0:\n",
    "        st.write(\"The Person is Healthy\")\n",
    "    if prediction==1:\n",
    "        st.write(\"The Person has Diabetes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54ff56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
